{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLimputer - Detailed Analysis\n",
    "\n",
    "This notebook provides an in-depth analysis of a single imputation strategy:\n",
    "1. Column-wise missing data analysis\n",
    "2. Cross-validation with detailed fold results\n",
    "3. Test set predictions and metrics\n",
    "4. Feature importance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from mlimputer import MLimputer\n",
    "from mlimputer.evaluation.cross_validation import CrossValidator, CrossValidationConfig\n",
    "from mlimputer.schemas.parameters import imputer_parameters\n",
    "from mlimputer.data.data_generator import ImputationDatasetGenerator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MLIMPUTER - DETAILED ANALYSIS\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset\n",
    "\n",
    "Binary classification with higher missing rate (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = ImputationDatasetGenerator(random_state=42)\n",
    "X, y = generator.quick_binary(n_samples=1500, missing_rate=0.20)\n",
    "\n",
    "print(f\"Dataset: {X.shape}\")\n",
    "print(f\"Missing: {X.isnull().sum().sum()} values ({X.isnull().sum().sum()/X.size:.1%})\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([X, y], axis=1)\n",
    "train_size = int(0.8 * len(data))\n",
    "train = data.iloc[:train_size].reset_index(drop=True)\n",
    "test = data.iloc[train_size:].reset_index(drop=True)\n",
    "\n",
    "print(f\"Training: {train.shape}\")\n",
    "print(f\"Test: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Random Forest Strategy\n",
    "\n",
    "Custom configuration with more estimators and depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = imputer_parameters()\n",
    "params[\"RandomForest\"][\"n_estimators\"] = 100\n",
    "params[\"RandomForest\"][\"max_depth\"] = 15\n",
    "params[\"RandomForest\"][\"min_samples_split\"] = 5\n",
    "\n",
    "print(\"Random Forest Configuration:\")\n",
    "for key, value in params[\"RandomForest\"].items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = MLimputer(\n",
    "    imput_model=\"RandomForest\",\n",
    "    imputer_configs=params\n",
    ")\n",
    "\n",
    "# Fit on train (excluding target)\n",
    "imputer.fit(X=train.drop(columns=['target']))\n",
    "\n",
    "# Transform both sets\n",
    "X_train_imputed = imputer.transform(X=train.drop(columns=['target']))\n",
    "X_test_imputed = imputer.transform(X=test.drop(columns=['target']))\n",
    "\n",
    "print(f\"\\n✓ Training imputed: {train.drop(columns=['target']).isnull().sum().sum()} → 0 missing\")\n",
    "print(f\"✓ Test imputed: {test.drop(columns=['target']).isnull().sum().sum()} → 0 missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column-wise Missing Data Analysis\n",
    "\n",
    "Identify which columns had the most missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_missing = train.drop(columns=['target']).isnull().sum()\n",
    "train_missing = train_missing[train_missing > 0].sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 10 columns with missing values:\")\n",
    "for col, count in train_missing.head(10).items():\n",
    "    pct = (count / len(train)) * 100\n",
    "    print(f\"  {col}: {count} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation Analysis\n",
    "\n",
    "5-fold CV with detailed fold-by-fold results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add target back for CV\n",
    "X_train_imputed['target'] = train['target'].values\n",
    "\n",
    "cv_config = CrossValidationConfig(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "validator = CrossValidator(config=cv_config)\n",
    "model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "cv_results = validator.validate(\n",
    "    X=X_train_imputed,\n",
    "    target='target',\n",
    "    models=[model],\n",
    "    problem_type='binary_classification'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fold-by-Fold Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard = validator.get_leaderboard()\n",
    "\n",
    "print(\"\\nFold-by-Fold Performance:\")\n",
    "fold_results = leaderboard[leaderboard['Fold'] != 'Aggregate']\n",
    "fold_results[['Fold', 'f1', 'accuracy', 'precision', 'recall']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAggregate Cross-Validation Results:\")\n",
    "agg_results = leaderboard[leaderboard['Fold'] == 'Aggregate']\n",
    "agg_results[['F1 Mean', 'ACCURACY Mean', 'PRECISION Mean', 'RECALL Mean']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Prediction\n",
    "\n",
    "Train final model and evaluate on holdout test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "final_model.fit(X_train_imputed.drop(columns=['target']), train['target'])\n",
    "\n",
    "y_pred = final_model.predict(X_test_imputed)\n",
    "y_true = test['target']\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=['Actual 0', 'Actual 1'],\n",
    "    columns=['Predicted 0', 'Predicted 1']\n",
    ")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis\n",
    "\n",
    "Identify which features are most important for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = final_model.feature_importances_\n",
    "feature_names = X_train_imputed.drop(columns=['target']).columns\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "feature_importance_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = imputer.get_summary()\n",
    "\n",
    "print(\"\\nImputation Summary:\")\n",
    "print(f\"  Strategy: {summary['model']}\")\n",
    "print(f\"  Columns imputed: {summary['n_columns_imputed']}\")\n",
    "print(f\"  Fit timestamp: {summary['fit_timestamp']}\")\n",
    "print(f\"  Status: {summary['status']}\")\n",
    "print(\"\\n✓ Detailed analysis completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}